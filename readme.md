
# ðŸ›£ï¸ IDD Detection with YOLOv5

This project uses **YOLOv5** to train an object detection model on the **Indian Driving Dataset (IDD)** (mini version).  
The goal is to detect and classify various road objects from dashcam images.

---

## ðŸ“‚ Project Structure

```
IDD_Detection/
â”‚
â”œâ”€â”€ yolov5/                       # YOLOv5 repository
â”‚   â”œâ”€â”€ data/                     # Dataset config YAML files
â”‚   â”œâ”€â”€ models/                   # Model config files
â”‚   â”œâ”€â”€ utils/                    # Utility scripts
â”‚   â””â”€â”€ runs/                     # Training & evaluation outputs
â”‚
â”œâ”€â”€ mini_dataset/                 # Mini IDD dataset
â”‚   â”œâ”€â”€ images/
    â”‚   |â”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â””â”€â”€ labels/
        |â”€â”€ test/
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”‚
|â”€â”€ data_pipeline/
|â”€â”€ train_model.py/
|â”€â”€ main.py/
|â”€â”€ run_inference.py/
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

1. Clone YOLOv5 and navigate into the repo:
```bash
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
```

2. Create and activate a virtual environment:

```bash
python -m venv .venv
.venv\Scripts\activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ðŸš€ Training

Run the training on your dataset:

```bash
python train.py --img 640 --batch 16 --epochs 50 --data data/idd.yaml --weights yolov5s.pt
```

* `--img`: image size
* `--batch`: batch size
* `--epochs`: number of training epochs
* `--data`: dataset YAML file
* `--weights`: pre-trained weights to start from (`yolov5s.pt` for small model)

---

## ðŸ“Š Results & Outputs

After training, results are stored in:

```
yolov5/runs/train/expX/
```

Key files:

* `results.png` â†’ Training curves (loss, mAP, precision, recall)
* `confusion_matrix.png` â†’ Confusion matrix of predictions
* `PR_curve.png` â†’ Precision-Recall curves per class
* `labels.jpg` â†’ Distribution of bounding boxes in the dataset
* `best.pt` â†’ Best model weights (highest mAP)
* `last.pt` â†’ Last epoch weights

Example training curve (`results.png`):
![results](yolov5/runs/train/exp2/results.png)

Example confusion matrix (`confusion_matrix.png`):
![confusion matrix](yolov5/runs/train/exp2/confusion_matrix.png)

---

## ðŸ§ª Evaluation

To evaluate your trained model and generate a confusion matrix:

```bash
python confusion_matrix.py --weights yolov5/runs/train/exp2/weights/best.pt --data yolov5/data/idd.yaml --device 0
```

> **Tip:** If you don't have a GPU, this will run slowly on CPU.
> For faster evaluation, use a cloud GPU (Google Colab / Kaggle).

---

## ðŸ“¦ Inference

Run detection on new images:

```bash
python yolov5/detect.py --weights yolov5/runs/train/exp2/weights/best.pt --source path/to/images
```

---

## ðŸ’¡ Notes

* This project used the **Mini IDD dataset** for faster experiments.
* For better accuracy, use the full dataset and a larger YOLOv5 model (e.g., `yolov5m.pt`, `yolov5l.pt`).
* The confusion matrix in `yolov5/runs/train/exp2/confusion_matrix.png` is already generated at the end of training â€” no need to re-run unless testing new weights/dataset.

---

## ðŸ“œ License

This project follows the [GPL-3.0 license](yolov5/LICENSE) from the YOLOv5 repository.

---
